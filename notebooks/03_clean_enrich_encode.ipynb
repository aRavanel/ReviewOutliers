{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning, enrichment and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.config import BASE_PATH_DATA, PATH_PROJECT\n",
    "os.chdir(PATH_PROJECT)\n",
    "\n",
    "file_path_train_raw = os.path.join(BASE_PATH_DATA, 'processed', 'train.parquet')\n",
    "file_path_test_raw = os.path.join(BASE_PATH_DATA, 'processed', 'test.parquet')\n",
    "\n",
    "file_path_train_encoded = os.path.join(BASE_PATH_DATA, 'processed', f'df_train_encoded.parquet')\n",
    "file_path_test_encoded = os.path.join(BASE_PATH_DATA, 'processed', f'df_test_encoded.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:07:44,774 - src.config - DEBUG - calling load_dataframe\n",
      "2024-08-06 20:07:44,777 - src.config - INFO - Current working directory: C:\\Users\\alexi\\WORKSPACE\\interview_abwaab\\ReviewOutliers\n",
      "2024-08-06 20:08:05,508 - src.config - DEBUG - calling load_dataframe\n",
      "2024-08-06 20:08:05,510 - src.config - INFO - Current working directory: C:\\Users\\alexi\\WORKSPACE\\interview_abwaab\\ReviewOutliers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title_review</th>\n",
       "      <th>text</th>\n",
       "      <th>images_review</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>...</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images_metadata</th>\n",
       "      <th>videos</th>\n",
       "      <th>store</th>\n",
       "      <th>categories</th>\n",
       "      <th>details</th>\n",
       "      <th>bought_together</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458084</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Saved the day! And my wallet!</td>\n",
       "      <td>I just spent a LOT of money ordering Christmas...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07V45LJQ5</td>\n",
       "      <td>B07V45LJQ5</td>\n",
       "      <td>AG7JXXZEUKYYOJL7KH7LIFXHDR7Q</td>\n",
       "      <td>1669316848325</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29.97</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "      <td>{'title': ['  8544771 Dryer Heating Element, 2...</td>\n",
       "      <td>AMI PARTS</td>\n",
       "      <td>[Appliances, Parts &amp; Accessories, Dryer Parts ...</td>\n",
       "      <td>{\"Manufacturer\": \"AMI PARTS\", \"Part Number\": \"...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                   title_review  \\\n",
       "458084     5.0  Saved the day! And my wallet!   \n",
       "\n",
       "                                                     text images_review  \\\n",
       "458084  I just spent a LOT of money ordering Christmas...            []   \n",
       "\n",
       "              asin parent_asin                       user_id      timestamp  \\\n",
       "458084  B07V45LJQ5  B07V45LJQ5  AG7JXXZEUKYYOJL7KH7LIFXHDR7Q  1669316848325   \n",
       "\n",
       "        helpful_vote  verified_purchase  ... description  price  \\\n",
       "458084             2               True  ...          []  29.97   \n",
       "\n",
       "                                          images_metadata  \\\n",
       "458084  {'hi_res': ['https://m.media-amazon.com/images...   \n",
       "\n",
       "                                                   videos      store  \\\n",
       "458084  {'title': ['  8544771 Dryer Heating Element, 2...  AMI PARTS   \n",
       "\n",
       "                                               categories  \\\n",
       "458084  [Appliances, Parts & Accessories, Dryer Parts ...   \n",
       "\n",
       "                                                  details bought_together  \\\n",
       "458084  {\"Manufacturer\": \"AMI PARTS\", \"Part Number\": \"...            None   \n",
       "\n",
       "       subtitle author  \n",
       "458084     None   None  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.utils.io.io import load_dataframe\n",
    "\n",
    "# read json file into dataframe\n",
    "df_train = load_dataframe(file_path_train_raw)\n",
    "df_test = load_dataframe(file_path_test_raw)\n",
    "\n",
    "# limit to wanted sample size, random_state for reproducibility\n",
    "df_train = df_train.sample(n=max_samples, random_state=42)\n",
    "df_test = df_test.sample(n=max_samples, random_state=42)\n",
    "\n",
    "display(df_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\reviewoutliers-SwZO3ms--py3.12\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-08-06 20:08:22,747 - datasets - INFO - PyTorch version 2.3.1 available.\n",
      "2024-08-06 20:08:26,587 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2024-08-06 20:08:26,596 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: Alibaba-NLP/gte-base-en-v1.5\n",
      "2024-08-06 20:08:26,614 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-06 20:08:27,037 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/modules.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:27,345 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/config_sentence_transformers.json HTTP/11\" 404 0\n",
      "2024-08-06 20:08:27,658 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/README.md HTTP/11\" 200 0\n",
      "2024-08-06 20:08:27,961 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/modules.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:28,267 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/sentence_bert_config.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:28,574 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/config.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:28,881 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/new-impl/resolve/main/configuration.py HTTP/11\" 200 0\n",
      "2024-08-06 20:08:29,193 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/config.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:30,315 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/new-impl/resolve/main/modeling.py HTTP/11\" 200 0\n",
      "2024-08-06 20:08:31,396 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /Alibaba-NLP/gte-base-en-v1.5/resolve/main/tokenizer_config.json HTTP/11\" 200 0\n",
      "2024-08-06 20:08:31,807 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /api/models/Alibaba-NLP/gte-base-en-v1.5/revision/main HTTP/11\" 200 148886\n",
      "2024-08-06 20:08:33,083 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /api/models/Alibaba-NLP/gte-base-en-v1.5 HTTP/11\" 200 148886\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\alexi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "2024-08-06 20:08:33,497 - src.config - DEBUG - calling preprocess_data\n",
      "2024-08-06 20:08:33,501 - src.config - DEBUG - calling clean_enrich\n",
      "2024-08-06 20:08:33,637 - src.config - DEBUG - computing review embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7d8523133545f588e33797b5e67cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:16:47,648 - src.config - DEBUG - computing metadata embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66b3023f3054bcaa3ffaf2cd7b6ad1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:19:21,596 - src.config - DEBUG - calling encode_data\n",
      "2024-08-06 20:19:21,616 - src.config - DEBUG - calling preprocess_data\n",
      "2024-08-06 20:19:21,617 - src.config - DEBUG - calling clean_enrich\n",
      "2024-08-06 20:19:21,647 - src.config - DEBUG - computing review embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97998fb4e81f44fe8b736aae69b9d72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:32:02,190 - src.config - DEBUG - computing metadata embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b3dc9cf149486182d8dfa4d6e241a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 20:35:19,893 - src.config - DEBUG - calling encode_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df_train_encoded dataset: (1000, 303)\n",
      "length of df_test_encoded dataset: (1000, 303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_293</th>\n",
       "      <th>feature_294</th>\n",
       "      <th>feature_295</th>\n",
       "      <th>feature_296</th>\n",
       "      <th>feature_297</th>\n",
       "      <th>feature_298</th>\n",
       "      <th>feature_299</th>\n",
       "      <th>feature_300</th>\n",
       "      <th>feature_301</th>\n",
       "      <th>feature_302</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080945</td>\n",
       "      <td>0.291911</td>\n",
       "      <td>0.315864</td>\n",
       "      <td>0.250526</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.171611</td>\n",
       "      <td>0.610187</td>\n",
       "      <td>-0.389288</td>\n",
       "      <td>-0.41343</td>\n",
       "      <td>-0.13935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.080945   0.291911   0.315864   0.250526     0.1965   0.171611   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_293  feature_294  \\\n",
       "0   0.610187  -0.389288   -0.41343   -0.13935  ...          0.0          0.0   \n",
       "\n",
       "   feature_295  feature_296  feature_297  feature_298  feature_299  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_300  feature_301  feature_302  \n",
       "0          0.0          0.0          0.0  \n",
       "\n",
       "[1 rows x 303 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.preprocessing.preprocessing import preprocess_data\n",
    "\n",
    "# encode the data\n",
    "df_train_encoded = preprocess_data(df_train, training=True)\n",
    "saved_name = os.path.join(BASE_PATH_DATA, 'processed', 'df_test_enriched.parquet')\n",
    "df_test_encoded = preprocess_data(df_test, training=False, saved_name=saved_name)\n",
    "\n",
    "# print some stats\n",
    "print(f'length of df_train_encoded dataset: {df_train_encoded.shape}')\n",
    "print(f'length of df_test_encoded dataset: {df_test_encoded.shape}')\n",
    "display(df_train_encoded.head(1))\n",
    "\n",
    "# Save the combined dataset (if needed)\n",
    "df_train_encoded.to_parquet(file_path_train_encoded, index=False)\n",
    "df_test_encoded.to_parquet(file_path_test_encoded, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewoutliers-SwZO3ms--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
