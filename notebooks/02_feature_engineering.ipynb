{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_review = \"Subscription_Boxes_review.json\"\n",
    "file_name_metadata = \"Subscription_Boxes_metadata.json\"\n",
    "embedder_name = 'all-MiniLM-L6-v2'  # dim : 384, max_len : 256 (probably too short for some cases)\n",
    "\n",
    "max_samples = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexi\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\reviewoutliers-SwZO3ms--py3.12\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = SentenceTransformer(embedder_name)  # A good balance between performance and dimensionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import process\n",
    "\n",
    "\n",
    "base_folder = os.path.join('..', 'data', 'raw')\n",
    "\n",
    "# create paths\n",
    "review_file_path = os.path.join(base_folder, file_name_review)\n",
    "metadata_file_path = os.path.join(base_folder, file_name_metadata)\n",
    "\n",
    "# read json file into dataframe\n",
    "df_metadata = pd.read_json(metadata_file_path)\n",
    "df_review = pd.read_json(review_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand timestamp\n",
    "df_review['timestamp'] = pd.to_datetime(df_review['timestamp'], unit='ms')  # Convert Unix timestamp to datetime\n",
    "df_review['year'] = df_review['timestamp'].dt.year\n",
    "df_review['month'] = df_review['timestamp'].dt.month\n",
    "df_review['day'] = df_review['timestamp'].dt.day\n",
    "df_review['hour'] = df_review['timestamp'].dt.hour\n",
    "\n",
    "# Handle missing values (ugly, to fix later)\n",
    "# -> if str fill with empty string\n",
    "# -> if numeric or categorical: fill with a dummy value\n",
    "df_review['year'] = df_review['year'].fillna(-1).astype('int')\n",
    "df_review['month'] = df_review['month'].fillna(-1).astype('int')\n",
    "df_review['day'] = df_review['day'].fillna(-1).astype('int')\n",
    "df_review['hour'] = df_review['hour'].fillna(-1).astype('int')\n",
    "df_review['rating'] = df_review['rating'].fillna(-1).astype('int')\n",
    "df_review['title'] = df_review['title'].fillna('').astype('str')\n",
    "df_review['text'] = df_review['text'].fillna('').astype('str')\n",
    "df_review['user_id'] = df_review['user_id'].fillna('').astype('str')\n",
    "df_review['helpful_vote'] = df_review['helpful_vote'].fillna(-1).astype('int')\n",
    "df_review['verified_purchase'] = df_review['verified_purchase'].fillna(-1).astype('int')\n",
    "\n",
    "# concatenate some text together\n",
    "# -> this way less features because each embeddings is of high dimensionality\n",
    "df_review['review_text'] = df_review['title'] + '/n/n' + df_review['text']\n",
    "\n",
    "# drop some features:\n",
    "# - timestamp: tranformed\n",
    "# - images: too complex\n",
    "# - user_id: not informative\n",
    "features_drop = ['timestamp', 'text', 'title']\n",
    "features_drop += ['images', 'user_id']\n",
    "df_review = df_review.drop(columns=features_drop)\n",
    "\n",
    "# Drop some elements that cannot be used\n",
    "df_review.drop_duplicates(inplace=True)\n",
    "df_review = df_review.dropna(subset=['asin', 'parent_asin'])  # drop if 'asin' or 'parent_asin'  not filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# features -> concatenated in a string\n",
    "df_metadata['main_category'] = df_metadata['main_category'].fillna('').astype('category')\n",
    "df_metadata['title'] = df_metadata['title'].fillna('').astype('str')\n",
    "df_metadata['average_rating'] = df_metadata['average_rating'].fillna(-1).astype('float')\n",
    "df_metadata['rating_number'] = df_metadata['rating_number'].fillna(-1).astype('int')\n",
    "df_metadata['features'] = df_metadata['features'].apply(lambda x: ' '.join(x) if isinstance(x, list) and x else '').astype('str')\n",
    "df_metadata['store'] = df_metadata['store'].fillna('').astype('category')\n",
    "df_metadata['parent_asin'] = df_metadata['parent_asin'].fillna('').astype('str')\n",
    "#df_metadata['description'] = df_metadata['description'].fillna('')\n",
    "#df_metadata['price'] = df_metadata['price'].fillna(0)\n",
    "\n",
    "# concatenate some text together\n",
    "# -> this way less features because each embeddings is of high dimensionality\n",
    "df_metadata['metadata_text'] = df_metadata[['title','features']].astype(str).agg('/n/n'.join, axis=1)\n",
    "\n",
    "# Drop some features\n",
    "# - `images` (list of str): too complex\n",
    "# - `videos` (list of str): too complex\n",
    "# - `details` (dict): mostly empty\n",
    "# - `categories`: mostly empty\n",
    "# - `bought_together` (boolean): mostly empty\n",
    "# - `price` (float): mostly empty\n",
    "# - `description` (list of str): mostly empty\n",
    "features_to_drop = ['title', 'features']\n",
    "features_to_drop += ['images', 'videos', 'details', 'categories', 'bought_together', 'price', 'description']\n",
    "df_metadata = df_metadata.drop(columns=features_to_drop)\n",
    "\n",
    "# Drop duplicates\n",
    "df_metadata.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows if 'asin' or 'parent_asin' are not filled\n",
    "df_metadata = df_metadata.dropna(subset=['parent_asin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>review_text</th>\n",
       "      <th>main_category</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>store</th>\n",
       "      <th>metadata_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B07G584SHG</td>\n",
       "      <td>B09WC47S3V</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>USELESS/n/nAbsolutely useless nonsense and a c...</td>\n",
       "      <td>SUBSCRIPTION BOXES</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2962</td>\n",
       "      <td>KitNipBox</td>\n",
       "      <td>KitNipBox | Happy Cat Box | Monthly Cat Subscr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating        asin parent_asin  helpful_vote  verified_purchase  year  \\\n",
       "0       1  B07G584SHG  B09WC47S3V             2                  1  2020   \n",
       "\n",
       "   month  day  hour                                        review_text  \\\n",
       "0     10    8     5  USELESS/n/nAbsolutely useless nonsense and a c...   \n",
       "\n",
       "        main_category  average_rating  rating_number      store  \\\n",
       "0  SUBSCRIPTION BOXES             4.1           2962  KitNipBox   \n",
       "\n",
       "                                       metadata_text  \n",
       "0  KitNipBox | Happy Cat Box | Monthly Cat Subscr...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['rating', 'helpful_vote', 'verified_purchase', 'year', 'month', 'day', 'hour', 'average_rating', 'rating_number']\n",
      "Categorical features: ['main_category', 'store']\n",
      "Textual features: ['asin', 'parent_asin', 'review_text', 'metadata_text']\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on 'parent_asin' with suffixes for duplicate columns\n",
    "merged_df = pd.merge(df_review, df_metadata, on='parent_asin', how='inner', suffixes=('_review', '_metadata'))\n",
    "display(merged_df.head(1))\n",
    "\n",
    "# limit to wanted sample size\n",
    "merged_df = merged_df.sample(n=max_samples, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# list feature types\n",
    "# Automatically retrieve column types\n",
    "numerical_features = merged_df.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = merged_df.select_dtypes(include=['category', 'bool']).columns.tolist()\n",
    "textual_features = merged_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Textual features:\", textual_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings of textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accf327ca86b404a89544b292b49c966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397c2ec2da744eb8bd7b94e989d8018f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_embeddings = model.encode(merged_df['review_text'].tolist(), show_progress_bar=True)\n",
    "metadata_embeddings = model.encode(merged_df['metadata_text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Scale Text Embeddings: \n",
    "# - possibility A:Ensure the text embeddings have unit variance as a group. + weighting\n",
    "# - possibility B:if already in [-1, 1], just do weighting to keep hyperspace geometry\n",
    "embedding_size = model.get_sentence_embedding_dimension()\n",
    "review_embeddings_scaled = review_embeddings/embedding_size\n",
    "metadata_embeddings_scaled = metadata_embeddings/embedding_size\n",
    "\n",
    "# Other solution : add some similarity score such as\n",
    "# - positive_review\n",
    "# - similarity to description\n",
    "# - language\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data encoding and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Directly scale numerical data : remove the mean and scale to unit variance\n",
    "scaler_numerical = StandardScaler()\n",
    "X_numerical = merged_df[numerical_features].values\n",
    "X_numerical_standardized = scaler_numerical.fit_transform(X_numerical)\n",
    "\n",
    "# Scale Encoded Categorical Features\n",
    "# After encoding (ex for OH), scale each group of categorical features so that the entire group has unit variance.\n",
    "# Note : TODO could use different scaler if too big number of categories\n",
    "# TODO: save the encoders for future use (inference)\n",
    "\n",
    "categorical_encoder_list = []\n",
    "X_categorical_scaled = []\n",
    "for cat_feature in categorical_features:\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(merged_df[[cat_feature]])\n",
    "    num_categories = encoded_data.shape[1]\n",
    "    scaled_data = encoded_data / num_categories\n",
    "    X_categorical_scaled.append(scaled_data)\n",
    "    categorical_encoder_list.append(encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into a single dataset \n",
    "# Note : \n",
    "# - if sparse use hstack of scipy, else numpy\n",
    "# - X_categorical_scaled is a list of arrays -> need to put it in a single array\n",
    "\n",
    "X_combined = np.hstack((\n",
    "    X_numerical_standardized, \n",
    "    np.hstack(X_categorical_scaled),\n",
    "    review_embeddings_scaled,\n",
    "    metadata_embeddings_scaled,\n",
    "    ))\n",
    "combined_df = pd.DataFrame(X_combined, columns=[f'feature_{i}' for i in range(X_combined.shape[1])])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of combined dataset: (1000, 943)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_933</th>\n",
       "      <th>feature_934</th>\n",
       "      <th>feature_935</th>\n",
       "      <th>feature_936</th>\n",
       "      <th>feature_937</th>\n",
       "      <th>feature_938</th>\n",
       "      <th>feature_939</th>\n",
       "      <th>feature_940</th>\n",
       "      <th>feature_941</th>\n",
       "      <th>feature_942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782901</td>\n",
       "      <td>-0.158229</td>\n",
       "      <td>-2.645751</td>\n",
       "      <td>2.044837</td>\n",
       "      <td>-0.719922</td>\n",
       "      <td>-0.430744</td>\n",
       "      <td>0.741478</td>\n",
       "      <td>-0.140808</td>\n",
       "      <td>-0.828933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.782901  -0.158229  -2.645751   2.044837  -0.719922  -0.430744   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_933  feature_934  \\\n",
       "0   0.741478  -0.140808  -0.828933        1.0  ...    -0.000065     0.000011   \n",
       "\n",
       "   feature_935  feature_936  feature_937  feature_938  feature_939  \\\n",
       "0    -0.000099    -0.000115     0.000431     -0.00009      0.00007   \n",
       "\n",
       "   feature_940  feature_941  feature_942  \n",
       "0    -0.000157    -0.000043    -0.000002  \n",
       "\n",
       "[1 rows x 943 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print some stats\n",
    "n_samples = combined_df.shape[0]\n",
    "print(f'length of combined dataset: {combined_df.shape}')\n",
    "display(combined_df.head(1))\n",
    "\n",
    "# Save the combined dataset (if needed)\n",
    "file_name = os.path.join('..', 'data', 'processed', f'combined_dataset_{n_samples}.parquet')\n",
    "combined_df.to_parquet(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewoutliers-SwZO3ms--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
